---
layout: posts
title:  ""
date: 2024-03-08
categories: 中间件
tags: [中间件,kafka]
excerpt: 
---

## 书籍推荐

Apache%20Kafka实战%20(胡夕 ****

kafka权威指南 **



[https://blog.csdn.net/Liu_Fang_Hong/article/details/132147387](https:/blog.csdn.net/Liu_Fang_Hong/article/details/132147387)

[https://cloud.tencent.com/developer/article/1814830](https:/cloud.tencent.com/developer/article/1814830)

- spring boot 使用Kafka [https://blog.csdn.net/yy8623977/article/details/127950423](https:/blog.csdn.net/yy8623977/article/details/127950423)
- [https://tech.meituan.com/2015/01/13/kafka-fs-design-theory.html](https:/tech.meituan.com/2015/01/13/)
- [https://blog.csdn.net/l123lgx/article/details/131206347](https:/blog.csdn.net/l123lgx/article/details/131206347)

## 消息范形

- 点对点
- 发布订阅

![](../../.images/18e9c6a2d48.png)

## Linux上使用kafka

- 创建topic

`kafka-topics.sh --create --zookeeper 192.168.1.150:2181,192.168.1.150:2182 --replication-factor 1 --partitions 3 --topic test`

- 查看topic

`kafka-topics.sh --list --zookeeper 192.168.1.150:2181,192.168.1.150:2182`

- 查看topic详细信息

`kafka-topics.sh --describe --topic test --zookeeper 192.168.1.150:2181,192.168.1.150:2182`

- 测试发布消息

`kafka-console-producer.sh --broker-list 192.168.1.150:9092 --topic test`

- 测试接收消息

`kafka-console-consumer.sh --bootstrap-server 192.168.1.150:9092 --topic test --from-beginning`

- 修改分区数量

  `kafka-topics.sh --zookeeper 192.168.1.150:2181,192.168.1.150:2182 --alter --topic test --partitions [数量]`

  删除指定的Topic


`kafka-topics.sh --delete --zookeeper 192.168.1.150:2181,192.168.1.150:2182 --topic [topic名字]`

- 查看当前主题下有哪些消费组

  `kafka-consumer-groups.sh --bootstrap-server 192.168.1.150:9092 --list`

- 查看消费组的详细信息

  `kafka-consumer-groups.sh --bootstrap-server 192.168.1.150:9092 --describe --group myGroup`

  ````
  [root@localhost bin]# kafka-consumer-groups.sh --bootstrap-server 192.168.1.150:9092 --describe --group myGroup
  
  Consumer group 'myGroup' has no active members.
  
  GROUP           TOPIC           PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG             CONSUMER-ID     HOST            CLIENT-ID
  myGroup         test            1          2               2               0               -               -               -
  myGroup         test            0          5               5               0               -               -               -
  myGroup         test            2          4               4               0               -               -               -
  
  ````

- 查看所有的消费组

  `kafka-consumer-groups.sh --bootstrap-server 192.168.1.150:9092 --list`


## 记录

消息中的key：当producer发送消息给broker的时候根据这个key的hash来计算向topic的哪个分区写入消息

````
				  如果没有指定则默认是轮询的，保证均衡
````

ISP: 只有leader副本才能响应写入的请求，其他的都与leader保持同步

![](../../.images/18e9a66b315.png)

同步发送

异步发送+回调

fire and forget不建用使用 即发送后不关发送情况

acks: leader broker何时发送写入结果给producer

## SpringBoot使用配置Kafka

1. pom.xml

   ```xml
       <dependencies>
           <dependency>
               <groupId>org.springframework.boot</groupId>
               <artifactId>spring-boot-starter-web</artifactId>
               <version>2.0.0.RELEASE</version>
           </dependency>
           <dependency>
               <groupId>org.springframework.kafka</groupId>
               <artifactId>spring-kafka</artifactId>
               <version>2.8.3</version>
           </dependency>
           <dependency>
               <groupId>org.springframework.kafka</groupId>
               <artifactId>spring-kafka-test</artifactId>
               <scope>test</scope>
           </dependency>
       </dependencies>
   ```

2. application.yml

   ```yml
   spring:
     profiles:
       active: dev
     kafka:
       bootstrap-servers: 192.168.1.150:9092
       producer:
         retries: 0
         acks: 1
         batch-size: 16384
         buffer-memory: 33554432
   
       consumer:
         group-id: "myGroup"
         enable-auto-commit: true
         auto-commit-interval: 100
   ```

3. Producer

   ```java
   @RestController
   public class Producer {
       @Autowired
       private KafkaTemplate<String, Object> kafkaTemplate;
       // 发送消息
       @GetMapping("/send/{msg}")
       public void sendMessage1(@PathVariable("msg") String msg) {
           kafkaTemplate.send("test", msg);
       }
   }
   ```

4. Consumer

   ```java
   @Component
   public class Consumer {
       @KafkaListener(topics = {"test"})
       public void listen(ConsumerRecord<?, ?> record){
           // 消费的哪个topic、partition的消息,打印出消息内容
           System.out.println("简单消费："+record.topic()+"-"+record.partition()+"-"+record.value());
       }
   }
   ```

5. log中显示的配置

   ```yml
   2024-03-22 14:20:09.636  INFO 6808 --- [nio-9777-exec-5] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
       acks = 1
       batch.size = 16384
       bootstrap.servers = [192.168.1.150:9092]
       buffer.memory = 33554432
       client.dns.lookup = use_all_dns_ips
       client.id = producer-1
       compression.type = none
       connections.max.idle.ms = 540000
       delivery.timeout.ms = 120000
       enable.idempotence = false
       interceptor.classes = []
       key.serializer = class org.apache.kafka.common.serialization.StringSerializer
       linger.ms = 0
       max.block.ms = 60000
       max.in.flight.requests.per.connection = 5
       max.request.size = 1048576
       metadata.max.age.ms = 300000
       metadata.max.idle.ms = 300000
       metric.reporters = []
       metrics.num.samples = 2
       metrics.recording.level = INFO
       metrics.sample.window.ms = 30000
       partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
       receive.buffer.bytes = 32768
       reconnect.backoff.max.ms = 1000
       reconnect.backoff.ms = 50
       request.timeout.ms = 30000
       retries = 0
       retry.backoff.ms = 100
       sasl.client.callback.handler.class = null
       sasl.jaas.config = null
       sasl.kerberos.kinit.cmd = /usr/bin/kinit
       sasl.kerberos.min.time.before.relogin = 60000
       sasl.kerberos.service.name = null
       sasl.kerberos.ticket.renew.jitter = 0.05
       sasl.kerberos.ticket.renew.window.factor = 0.8
       sasl.login.callback.handler.class = null
       sasl.login.class = null
       sasl.login.refresh.buffer.seconds = 300
       sasl.login.refresh.min.period.seconds = 60
       sasl.login.refresh.window.factor = 0.8
       sasl.login.refresh.window.jitter = 0.05
       sasl.mechanism = GSSAPI
       security.protocol = PLAINTEXT
       security.providers = null
       send.buffer.bytes = 131072
       socket.connection.setup.timeout.max.ms = 30000
       socket.connection.setup.timeout.ms = 10000
       ssl.cipher.suites = null
       ssl.enabled.protocols = [TLSv1.2]
       ssl.endpoint.identification.algorithm = https
       ssl.engine.factory.class = null
       ssl.key.password = null
       ssl.keymanager.algorithm = SunX509
       ssl.keystore.certificate.chain = null
       ssl.keystore.key = null
       ssl.keystore.location = null
       ssl.keystore.password = null
       ssl.keystore.type = JKS
       ssl.protocol = TLSv1.2
       ssl.provider = null
       ssl.secure.random.implementation = null
       ssl.trustmanager.algorithm = PKIX
       ssl.truststore.certificates = null
       ssl.truststore.location = null
       ssl.truststore.password = null
       ssl.truststore.type = JKS
       transaction.timeout.ms = 60000
       transactional.id = null
       value.serializer = class org.apache.kafka.common.serialization.StringSerializer
   ```

6. 

## 1. 发送消息

### 1.1 发送消息的方式

1. 发送并忘记fire-and-forget
2. 同步发送 send().get()  会阻塞 不建议
3. 异步发送

![](../../.images/18e7358c8e1.png)

### 1.2 SpringBoot发送消息

- 同步发送

  ```java
  SendResult<String, Object> stringObjectSendResult = kafkaTemplate.send(Constants.FORM_OPERATION_TOPIC, message)
                      .get();
  ```

- 异步发送

  ```java
  kafkaTemplate.send("", new DemoProducerCallback());
  
  public class DemoProducerCallback implements Callback {
      
      @Override
      public void onCompletion(RecordMetadata recordMetadata, Exception e) {
          System.out.println("call back record");
          if (e != null) {
              e.printStackTrace();
          } else {
              if (e instanceof RetriableException) {
                  //处理瞬时异常
              } else {
                  //处理不可重试异常
              }
          }
      }
  }
  ```

- 事务发送

### 1.3 重要参数

1. <b><span style="color:rgba(244,63,94,1)">acks</span></b>

   指定了必须要有多少个分区副本收到消息，生产者才会认为消息写入是成功的

   acks=0，生产者在成功写入消息之前不会等待任何来自服务器的响应。

   acks=1，只要集群的首领节点收到消息，生产者就会收到一个来自服务器的成功响应。

   acks=all，只有当所有参与复制的节点全部收到消息时，生产者才会收到一个来自服务器的成功响应。

2. <b><span style="color:rgba(244,63,94,1)">buffer.memory</span></b>

   设置生产者内存缓冲区的大小

   设置 block.on.buffer.full 参数来决定缓存满了之后send()方法的调用阻塞还是异常

3. compression.type

默认情况下，消息发送时不会被压缩。该参数可以设置为 snappy、gzip 或 lz4，它指定了消息被发送给 broker 之前使用哪一种压缩算法进行压缩。

4. <b><span style="color:rgba(244,63,94,1)">retries</span></b>

   生产者可以重发消息的次数

   retry.backoff.ms 参数来设置重试的间隔时间

5. <b><span style="color:rgba(244,63,94,1)">batch.size</span></b>

   指定了一个批次可以使用的内存大小，按照字节数计算

6. linger.ms

   指定了生产者在发送批次之前等待更多消息加入批次的时间

7. client.id

   服务器会用它来识别消息的来源

8. max.in.flight.requests.per.connection

   指定了生产者在收到服务器响应之前可以发送多少个消息

9. timeout.ms、request.timeout.ms 和 metadata.fetch.timeout.ms
10. max.block.ms

指定了在调用 send() 方法或使用 partitionsFor() 方法获取元数据时生产者的阻塞时间。

11. max.request.size
12. receive.buffer.bytes 和 send.buffer.bytes

2024-03-25 11:20:39.150  INFO 12028 --- [           main] w.s.c.ServletWebServerApplicationContext : Root WebApplicationContext: initialization completed in 1292 ms

Loading class `com.mysql.jdbc.Driver'. This is deprecated. The new driver class is` com.mysql.cj.jdbc.Driver'. The driver is automatically registered via the SPI and manual loading of the driver class is generally unnecessary.

## 2. 消费消息

消费者的数量不要超过主题分区的数量

会造成消费者闲置

分区的所有权从一个消费者转移到另一个消费者，这样的行为被称为再均衡

consumer.subscribe("test.*");

线程安全  
在同一个群组里，我们无法让一个线程运行多个消费者，也无法让多个线  
程安全地共享一个消费者。按照规则，一个消费者使用一个线程。如果  
要在同一个消费者群组里运行多个消费者，需要让每个消费者运行在自己  
的线程里。最好是把消费者的逻辑封装在自己的对象里，然后使用 Java  
的 ExecutorService 启动多个线程，使每个消费者运行在自己的线程上。  
Confluent 的博客（[https://www.confluent.io/blog/）上有一个教程介绍如何处](https://www.confluent.io/blog/%EF%BC%89%E4%B8%8A%E6%9C%89%E4%B8%80%E4%B8%AA%E6%95%99%E7%A8%8B%E4%BB%8B%E7%BB%8D%E5%A6%82%E4%BD%95%E5%A4%84)  
理这种情况。

### 2.1 重要参数

1. fetch.min.bytes
2. fetch.max.wait.ms
3. max.partition.fetch.bytes
4. session.timeout.ms
5. auto.offset.reset

   该属性指定了消费者在读取一个没有偏移量的分区或者偏移量无效的情况下（因消费者长  
时间失效，包含偏移量的记录已经过时并被删除）该作何处理。

   - latest：消费者将从最新的记录开始读取数据
   - earliest：消费者将从起始位置读取分区的记录

6. enable.auto.commit

   尽量避免出现重复数据和数据丢失，可以把它设为 false，由自  
己控制何时提交偏移量。如果把它设为 true，还可以通过配置 auto.commit.interval.ms  
属性来控制提交的频率。

7. **partition.assignment.strategy（分区分配策略）**

   - Range：若干个连续的分区分配给消费者
   - RoundRobin：把主题的所有分区逐个分配给消费者

8. client.id
9. max.poll.records
10. receive.buffer.bytes 和 send.buffer.bytes

更新分区当前位置的操作叫作提交

要记住，commitSync() 将会提交由 poll() 返回的最新偏移量，所以在处理完所有记录后要  
确保调用了 commitSync()，否则还是会有丢失消息的风险。如果发生了再均衡，从最近一  
批消息到发生再均衡之间的所有消息都将被重复处理

SpringBoot如何使用，commitSync() 方法

异步提交

consumer.commitAsync();



提交特定的偏移量

　再均衡监听器

从特定偏移量处开始处理记录

Kafka 如何进行复制

•  Kafka 如何处理来自生产者和消费者的请求；  
•  Kafka 的存储细节，比如文件格式和索引。



![](../../.images/18e746d6b00.png)![](../../.images/18e746dd4c1.png)

## 保证消息不丢失

1. 要保证消息能正常发送给broker
2. 保证broker上的消息能够正常持久化

![](../../.images/18e9c7aabdb.png)

![](../../.images/18e9c7b1f61.png)

## 保证不重复消费

消费方进行幂等性校验

1. 数据库创建联合主键
2. 使用分布式锁

## 保证顺序消费

## 延迟队列

![](../../.images/18ec0e11267.png)

## 多线程消费